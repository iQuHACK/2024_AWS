{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a5e3586-54b9-44fd-99a2-994c14eca3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement results: Counter({'11': 412, '00': 395, '10': 108, '01': 85})\n"
     ]
    }
   ],
   "source": [
    "from braket.tracking import Tracker\n",
    "from braket.aws import AwsDevice\n",
    "from braket.circuits import Circuit, gates, noises, observables\n",
    "from braket.devices import LocalSimulator\n",
    "from braket.parametric import FreeParameter\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import unitary_group\n",
    "from braket.circuits.noise_model import (\n",
    "    GateCriteria,\n",
    "    NoiseModel,\n",
    "    ObservableCriteria,\n",
    ")\n",
    "from braket.circuits import Circuit, Observable, Gate, Noise\n",
    "from braket.circuits.noises import (\n",
    "    BitFlip,\n",
    "    Depolarizing,\n",
    "    TwoQubitDepolarizing,\n",
    "    Kraus,\n",
    ")\n",
    "from braket.devices import LocalSimulator\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "\n",
    "t = Tracker().start()\n",
    "\n",
    "# build a simple circuit\n",
    "circ = Circuit().h(0).cnot(0,1)\n",
    "\n",
    "# define a noise channel\n",
    "noise = noises.BitFlip(probability=0.1)\n",
    "\n",
    "# add noise to every gate in the circuit\n",
    "circ.apply_gate_noise(noise)\n",
    "\n",
    "# select the local noise simulator\n",
    "device = LocalSimulator('braket_dm')\n",
    "\n",
    "# run the circuit on the local simulator\n",
    "task = device.run(circ, shots = 1000)\n",
    "\n",
    "# visualize the results\n",
    "result = task.result()\n",
    "measurement = result.measurement_counts\n",
    "print('measurement results:', measurement)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ef0ae-584e-4caf-b898-ed594b7b6d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be80dbd-dccb-44a9-a49a-bd3a5a631660",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 8, 7, 0, 4, 3, 5, 6]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example graph representation\n",
    "# Nodes represent qubits, and edges represent crosstalk errors between qubits\n",
    "# nodes = {0: {'error': 0.1}, 1: {'error': 0.2}, ...}  # Node ID and its error percentage\n",
    "# edges = {(0, 1): 0.01, (0, 2): 0.02, ...}  # Tuple of node IDs and the error of the edge\n",
    "  # List of communities, each containing one node\n",
    "def calculate_eii_ai(communities, edges):\n",
    "    \"\"\"\n",
    "    Calculate e_ii and a_i for each community.\n",
    "    \n",
    "    Parameters:\n",
    "    - communities: List of lists, where each sublist represents a community and contains node IDs.\n",
    "    - edges: Dictionary with node ID pairs as keys and error percentages as values.\n",
    "    \n",
    "    Returns:\n",
    "    - e_ii_dict: Dictionary of e_ii values for each community.\n",
    "    - a_i_dict: Dictionary of a_i values for each community.\n",
    "    \"\"\"\n",
    "    total_weight = sum(edges.values())\n",
    "    e_ii_dict = {}\n",
    "    a_i_dict = {}\n",
    "    \n",
    "    for index, community in enumerate(communities):\n",
    "        internal_weight = 0\n",
    "        total_community_weight = 0\n",
    "        \n",
    "        # Calculate internal weights and total connected weights for each community\n",
    "        for i in community:\n",
    "            for j in community:\n",
    "                if i != j and (i, j) in edges:\n",
    "                    internal_weight += edges[(i, j)]\n",
    "            for k, v in edges.items():\n",
    "                if i in k:\n",
    "                    total_community_weight += v\n",
    "        \n",
    "        e_ii = internal_weight / total_weight\n",
    "        a_i = total_community_weight / total_weight\n",
    "        \n",
    "        e_ii_dict[index] = e_ii\n",
    "        a_i_dict[index] = a_i\n",
    "        \n",
    "    return e_ii_dict, a_i_dict\n",
    "\n",
    "def calculate_reward(community1, community2, communities, edges, nodes):\n",
    "    \"\"\"\n",
    "    Calculate the reward for merging two communities with additional reliability factors.\n",
    "\n",
    "    Parameters:\n",
    "    - community1, community2: Indices of the two communities to be merged.\n",
    "    - communities: Current list of all communities.\n",
    "    - edges: Dictionary with node ID pairs as keys and error percentages as values.\n",
    "    - nodes: Dictionary with node IDs as keys and their errors as values.\n",
    "\n",
    "    Returns:\n",
    "    - Reward value for merging the two communities, including reliability adjustments.\n",
    "    \"\"\"\n",
    "    # First, calculate original Q values as before\n",
    "    e_ii_dict, a_i_dict = calculate_eii_ai(communities, edges)\n",
    "    Q_origin = sum(e_ii_dict.values()) - sum(a_i ** 2 for a_i in a_i_dict.values())\n",
    "    \n",
    "    # Merge communities for Q_merged calculation\n",
    "    merged_community = communities[community1] + communities[community2]\n",
    "    temp_communities = [c for i, c in enumerate(communities) if i not in [community1, community2]]\n",
    "    temp_communities.append(merged_community)\n",
    "    e_ii_dict_merged, a_i_dict_merged = calculate_eii_ai(temp_communities, edges)\n",
    "    Q_merged = sum(e_ii_dict_merged.values()) - sum(a_i ** 2 for a_i in a_i_dict_merged.values())\n",
    "    \n",
    "    # Calculate V: Average reliability of readout operations on the qubits of the two communities\n",
    "    node_errors = [nodes[node]['error'] for node in merged_community]\n",
    "    V = 1 - sum(node_errors) / len(node_errors)  # Reliability is 1 - average error\n",
    "\n",
    "    # Calculate X: Average conditional reliability of CNOTs within each community\n",
    "    # that have crosstalk CNOT in the other community\n",
    "    internal_edges = [edges[edge] for edge in edges if edge[0] in merged_community and edge[1] in merged_community]\n",
    "    if internal_edges:\n",
    "        X = 1 - sum(internal_edges) / len(internal_edges)  # Reliability is 1 - average error\n",
    "    else:\n",
    "        X = 1  # Default to 1 if no internal edges, indicating perfect reliability\n",
    "    E = 0.95\n",
    "    omega = 0.4\n",
    "    # Update the reward function F to include X*V\n",
    "    F = (Q_merged - Q_origin) + (X * V *E*omega)\n",
    "    \n",
    "    return F\n",
    "\n",
    "\n",
    "def merge_communities(communities, edges):\n",
    "    if len(communities) <= 1:\n",
    "        return communities\n",
    "    \n",
    "    best_reward = None\n",
    "    to_merge = (None, None)\n",
    "\n",
    "    # Iterate over all pairs of communities to find the best merge based on the reward\n",
    "    for i in range(len(communities)):\n",
    "        for j in range(i + 1, len(communities)):\n",
    "            # Calculate the reward for merging these two communities\n",
    "            reward = calculate_reward(i, j, communities, edges, nodes)\n",
    "\n",
    "            # If this pair has the best reward so far, remember it\n",
    "            if best_reward is None or reward > best_reward:\n",
    "                best_reward = reward\n",
    "                to_merge = (i, j)\n",
    "\n",
    "    # Perform the merge if a beneficial merge is found\n",
    "    if to_merge[0] is not None:\n",
    "        new_community = communities[to_merge[0]] + communities[to_merge[1]]\n",
    "        # Create a new list of communities with the merged community replacing the original ones\n",
    "        updated_communities = [communities[i] for i in range(len(communities)) if i not in to_merge]\n",
    "        updated_communities.append(new_community)\n",
    "\n",
    "        # Recursively call the function with the updated list of communities\n",
    "        return merge_communities(updated_communities, edges)\n",
    "    else:\n",
    "        # If no beneficial merge is found, return the current communities\n",
    "        return communities\n",
    "\n",
    "import random\n",
    "\n",
    "# Generate nodes with random error percentages\n",
    "nodes = {i: {'error': random.uniform(0.01, 0.1)} for i in range(9)}\n",
    "\n",
    "# Generate edges with random error rates between some pairs of nodes\n",
    "edges = {}\n",
    "for i in range(8):  # Example connections, not fully connected graph\n",
    "    for j in range(i + 1, 9):\n",
    "        if random.random() > 0.5:  # Randomly decide if an edge should exist\n",
    "            edges[(i, j)] = random.uniform(0.001, 0.01)\n",
    "\n",
    "# Example output\n",
    "# print(\"Nodes:\", nodes)\n",
    "# print(\"Edges:\", edges)\n",
    "communities = [[node] for node in nodes] \n",
    "merge_communities(communities, edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db336e00-ac1a-4934-a57c-75697d0856db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = standard_noise_model()\n",
    "fiddy = get_two_qubit_fidelity(model, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df3a1c85-90ee-4f1f-9e26-a207fd998b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: {'children': (9, 6), 'community': [9, 6]}, 11: {'children': (8, 1), 'community': [8, 1]}, 12: {'children': (5, 11), 'community': [5, 8, 1]}, 13: {'children': (4, 10), 'community': [4, 9, 6]}, 14: {'children': (7, 2), 'community': [7, 2]}, 15: {'children': (12, 0), 'community': [5, 8, 1, 0]}, 16: {'children': (3, 13), 'community': [3, 4, 9, 6]}, 17: {'children': (14, 15), 'community': [7, 2, 5, 8, 1, 0]}, 18: {'children': (17, 16), 'community': [7, 2, 5, 8, 1, 0, 3, 4, 9, 6]}}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class HierarchyTree:\n",
    "    def __init__(self, num_nodes):\n",
    "        # Each node is initially its own community\n",
    "        self.nodes = {i: {'error': random.uniform(0.01, 0.1)} for i in range(num_nodes)}\n",
    "        fiddy = get_two_qubit_fidelity(model, len(self.nodes)) \n",
    "        self.edges = {(i, j): fiddy[i][j] for i in range(num_nodes) for j in range(i+1, num_nodes)}\n",
    "        self.communities = {i: [i] for i in range(num_nodes)}\n",
    "        self.tree = {}\n",
    "          \n",
    "        \n",
    "\n",
    "    def merge_communities(self):\n",
    "        while len(self.communities) > 1:\n",
    "            best_delta_q = float('-inf')\n",
    "            best_pair = None\n",
    "\n",
    "            # Calculate the best pair to merge\n",
    "            for i in self.communities:\n",
    "                for j in self.communities:\n",
    "                    if i != j:\n",
    "                        delta_q = self.calculate_delta_q(i, j)\n",
    "                        if delta_q > best_delta_q:\n",
    "                            best_delta_q = delta_q\n",
    "                            best_pair = (i, j)\n",
    "\n",
    "            if best_pair:\n",
    "                self._merge(best_pair)\n",
    "\n",
    "    def calculate_delta_q(self, comm1, comm2):\n",
    "        # Simplified version: Difference in internal vs. external connections\n",
    "        # Implement the actual FN algorithm's delta Q calculation here\n",
    "        return random.uniform(-0.01, 0.01)  # Placeholder\n",
    "\n",
    "    def _merge(self, pair):\n",
    "        new_comm = self.communities[pair[0]] + self.communities[pair[1]]\n",
    "        new_comm_id = max(self.communities.keys()) + 1\n",
    "        self.tree[new_comm_id] = {'children': pair, 'community': new_comm}\n",
    "        del self.communities[pair[0]]\n",
    "        del self.communities[pair[1]]\n",
    "        self.communities[new_comm_id] = new_comm\n",
    "\n",
    "    def get_hierarchy_tree(self):\n",
    "        return self.tree\n",
    "\n",
    "\n",
    "num_nodes = 10\n",
    "ht = HierarchyTree(num_nodes)\n",
    "ht.merge_communities()\n",
    "print(ht.get_hierarchy_tree())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d322cf72-c9e4-4e98-8798-cb2f8f9b7507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_fidelity(noise_model, qubit_1, qubit_2):\n",
    "    # Takes input of two qubits and calculates entangled gate fidelity\n",
    "    # qubit_1 and qubit_2 should be integer\n",
    "    \n",
    "    # set up device: Local Simulator\n",
    "    device = LocalSimulator()\n",
    "    device = LocalSimulator(backend=\"braket_dm\")\n",
    "    \n",
    "    c = Circuit().i(0).i(1).i(2).i(3).i(4).i(5).i(6).i(7).i(8).i(9).i(10).h(qubit_1).cnot(qubit_1, qubit_2)\n",
    "    \n",
    "    c = noise_model.apply(c)\n",
    "    \n",
    "    # run circuit (execute single TASK)\n",
    "    result = device.run(c, shots=10000).result()\n",
    "    \n",
    "    # get measurement shots\n",
    "    counts = result.measurement_counts\n",
    "    \n",
    "    # Extract top two count values from dictionary\n",
    "    fidelity_counts = tuple([value for key, value in sorted(counts.items(), key=lambda x: x[1], reverse=True)[:2]])\n",
    "    \n",
    "    \n",
    "    fidelity = (fidelity_counts[0]+fidelity_counts[1])/10000\n",
    "    \n",
    "    return fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785dfc96-a323-498f-b538-fb8a6dc87202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standard_noise_model():\n",
    "    rng = np.random.default_rng()\n",
    "    m = NoiseModel()\n",
    "    \n",
    "    two_q_depo_mu = 1 - 0.9311\n",
    "    two_q_depo_sigma = 0.005\n",
    "    bf_mu = 1 - 0.99752\n",
    "    bf_sigma = 0.0015\n",
    "    one_q_depo_mu = 1 - 0.9981\n",
    "    one_q_depo_sigma = 0.00017\n",
    "    for qi in range(11):\n",
    "        z_bf_prob = bf_mu + bf_sigma * rng.standard_normal()\n",
    "        z_bf_prob = 0.0 if z_bf_prob < 0.0 else z_bf_prob\n",
    "        \n",
    "        bf_prob = bf_mu + bf_sigma * rng.standard_normal()\n",
    "        bf_prob = 0.0 if bf_prob < 0.0 else bf_prob\n",
    "        \n",
    "        one_q_depo_prob = one_q_depo_mu + one_q_depo_sigma * rng.standard_normal()\n",
    "        one_q_depo_prob = 0.0 if one_q_depo_prob < 0.0 else one_q_depo_prob\n",
    "        \n",
    "        m.add_noise(BitFlip(z_bf_prob), ObservableCriteria(observables=Observable.Z, qubits=qi))\n",
    "        #m.add_noise(BitFlip(bf_prob), ObservableCriteria(qubits=qi))\n",
    "        \n",
    "        m.add_noise(Depolarizing(one_q_depo_prob), GateCriteria(qubits=qi))\n",
    "        for qj in range(11):\n",
    "            if not qj == qi:\n",
    "                two_q_depo_prob = two_q_depo_mu + two_q_depo_sigma * rng.standard_normal()\n",
    "                two_q_depo_prob = 0.0 if two_q_depo_prob < 0.0 else two_q_depo_prob\n",
    "                \n",
    "                m.add_noise(TwoQubitDepolarizing(two_q_depo_prob), GateCriteria(gates=[Gate.CNot, Gate.Swap, Gate.CPhaseShift], qubits=[qi, qj]))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b4892e-596f-4f82-adee-2f1a31b7fa67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_two_qubit_fidelity(noise_model, num_qubits):\n",
    "    \n",
    "    N = num_qubits\n",
    "    qubits = range(N)\n",
    "    fidelity_matrix = np.zeros((N, N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            fidelity = calculate_fidelity(noise_model, qubits[i], qubits[j])\n",
    "            fidelity_matrix[i][j] = fidelity\n",
    "            fidelity_matrix[j][i] = fidelity  # Symmetric\n",
    "\n",
    "    return fidelity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ad6e15-dedd-4948-a35d-312a3d438b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eba29d65-e8f4-4af5-94fd-c3ca516d9869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedyE_star(coupling_strength_matrix, hardware_graph):\n",
    "    \n",
    "    # Convert the coupling strength matrix to an edge list with weights\n",
    "    edges_with_weights = []\n",
    "    for i in range(len(coupling_strength_matrix)):\n",
    "        for j in range(i + 1, len(coupling_strength_matrix)):\n",
    "            weight = coupling_strength_matrix[i][j]\n",
    "            if weight > 0:\n",
    "                edges_with_weights.append(((i, j), weight))\n",
    "    # Sort the edges by weights in descending order\n",
    "    edges_with_weights.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Initialize the mapping of logical to physical qubits\n",
    "    qubit_mapping = {}\n",
    "    unmapped_qubits = set(range(len(coupling_strength_matrix)))\n",
    "    # Function to find the hardware location with maximum reliability\n",
    "    def find_max_reliability_location():\n",
    "        return 0\n",
    "    # Function to calculate the total reliability for a given qubit mapping\n",
    "    def calculate_total_reliability(qubit, mapped_qubits):\n",
    "        return 0\n",
    "    # Map the first edge with the highest weight\n",
    "    edge, _ = edges_with_weights[0]\n",
    "    qubit_mapping[edge[0]] = find_max_reliability_location()\n",
    "    unmapped_qubits.remove(edge[0])\n",
    "    # Map the rest of the qubits based on edge weights and reliability\n",
    "    for edge, weight in edges_with_weights:\n",
    "        for qubit in edge:\n",
    "            if qubit in unmapped_qubits:\n",
    "                # Find the best hardware location for the unmapped qubit\n",
    "                best_location = None\n",
    "                best_reliability = -1\n",
    "                for potential_location in hardware_graph:\n",
    "                    # Temporarily map the qubit to calculate reliability\n",
    "                    temp_mapping = qubit_mapping.copy()\n",
    "                    temp_mapping[qubit] = potential_location\n",
    "                    reliability = calculate_total_reliability(qubit, temp_mapping)\n",
    "                    if reliability > best_reliability:\n",
    "                        best_reliability = reliability\n",
    "                        best_location = potential_location\n",
    "                # Finalize the mapping for the qubit\n",
    "                qubit_mapping[qubit] = best_location\n",
    "                unmapped_qubits.remove(qubit)\n",
    "    return qubit_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959279c-5a5a-46f4-af2e-0ed2df2431c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CSM = [[0, 2, 2, 2], [2, 0, 2, 2], [2, 2, 0, 2], [2, 2, 2, 0]]\n",
    "\n",
    "# IL = {1: [(3, 2), (4, 4)], 0: [(0, 6)], 2: [(4, 4), (8, 2)], 3: [(2, 6)]}\n",
    "def sort_IL(input_map):\n",
    "\n",
    "    # Extract items from the map and sort them based on the first item of the tuple\n",
    "    sorted_items = sorted(input_map.items(), key=lambda x: x[1][0])\n",
    "\n",
    "    # Extract and return the sorted keys (rows)\n",
    "    sorted_keys = [item[0] for item in sorted_items]\n",
    "    return sorted_keys\n",
    "\n",
    "#P array sorted \n",
    "P = sort_IL(IL) #this works trust\n",
    "\n",
    "def ProgQdegree(int):\n",
    "    degree = 0\n",
    "    x = P[int]\n",
    "    for i in range(len(CSM)):\n",
    "        if CSM[x][i] != 0:\n",
    "            degree+=1\n",
    "    return degree\n",
    "print(ProgQdegree(1))\n",
    "        \n",
    "#iterate through all physical qbits from subgraph and calculate average CNOT error rates\n",
    "#get cnot error rates from all adjacent nodes to q, average them to find the CNOT error rate of that qbit\n",
    "\n",
    "#PhysErrorRates[] \n",
    "#do math here\n",
    "#adjacentCount = 0\n",
    "#nodeCount = 0\n",
    "#for node in subgraph:\n",
    "    #for adjacent in node.adjacent:\n",
    "        #PhysErrorRates[nodeCount] += adjacent.CNOTerror \n",
    "        #adjacentCount+=1\n",
    "    #PhysErrorRates[nodeCount] = #PhysErrorRates[nodeCount]/adjacentCount\n",
    "    #adjacentCount = 0\n",
    "    #nodeCount +=1\n",
    "    \n",
    "#list C, canidate qbits -- physical qubits whose degree is greater than or equal to the degree of the first pending program qubit in P;\n",
    "C = []\n",
    "for node in subgraph.node:\n",
    "    if node.degree >= P[0].degree:\n",
    "        C.append(node)\n",
    "    \n",
    "#If C is not empty, select the one with the lowest possible error rate in C\n",
    "#need to find a way to associate the error rate with C\n",
    "lowest = 100 #set high on purpose\n",
    "tempLowest = 100 #same as above\n",
    "if C:\n",
    "    for node in C:\n",
    "        if node.AvgError < lowest:\n",
    "            lowest = node.AvgError\n",
    "            selectedNode = node\n",
    "            \n",
    "else:\n",
    "    for node in C:\n",
    "        calculation = 1/((1-node.AvgError)*node.degree)\n",
    "        if calculation < tempLowest:\n",
    "            tempLowest = calculation\n",
    "            selectedNode = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e125ad-c0e4-46ed-8925-6924f5ecdf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def involved_qubits(IG):\n",
    "    setty = set([])\n",
    "    for i in IG:\n",
    "        for j in list(i.target):\n",
    "            setty.add(j)\n",
    "    return setty\n",
    "\n",
    "def cs_matrix(result_array,bell):\n",
    "    full = [set([int(entry) for entry in sublist]) for sublist in [list(item.target) for row in result_array for item in row]]\n",
    "    #full set of 2qubits in gate operation\n",
    "    coupling_strength_matrix=[[0 for _ in range(bell.qubit_count)] for _ in range(bell.qubit_count)]\n",
    "    for i in range(bell.qubit_count): #i is chosen as the index of the matrix\n",
    "        for j in range(bell.qubit_count): #j is chosen as the index of the matrix\n",
    "            #i or j is arbitray as it is symmetric\n",
    "            for pair in full:\n",
    "                if pair==set([i,j]):\n",
    "                    coupling_strength_matrix[i][j] += 1\n",
    "    return coupling_strength_matrix\n",
    "\n",
    "def algo_1(bell):\n",
    "\n",
    "    inst_list = bell.instructions\n",
    "\n",
    "    temp=[]\n",
    "    for key, value in bell.moments.items():\n",
    "        temp.append([key.time,value])\n",
    "\n",
    "\n",
    "    grouped_instructions = defaultdict(list)\n",
    "\n",
    "    for entry, instruction in temp:\n",
    "        grouped_instructions[entry].append(instruction)\n",
    "\n",
    "    result_array = list(grouped_instructions.values())\n",
    "\n",
    "    #mine just takes a gate set\n",
    "    IG = [] #1\n",
    "    IL = defaultdict(list)#[[] for _ in range (bell.qubit_count)]  #2\n",
    "    #ignoring 3\n",
    "    Gate_Set_Index = 0 #4\n",
    "    for i in result_array: #5\n",
    "        Gates_To_Remove = [] #6\n",
    "        for j in IG: #7\n",
    "            if len(j.target) == 2: #8 double check\n",
    "                Gates_To_Remove.append(j) #9\n",
    "            #10\n",
    "        #11\n",
    "        for j in i: #12\n",
    "            for k in list(j.target): #13\n",
    "                #14\n",
    "                if k in involved_qubits(IG): #15\n",
    "                    IL[int(k)][-1][1] += 1 #16\n",
    "                else: #17\n",
    "                    IL[int(k)].append([Gate_Set_Index,1]) #18\n",
    "                #19\n",
    "            #20\n",
    "        #21\n",
    "        for j in Gates_To_Remove: #22\n",
    "            IG.remove(j) #23\n",
    "        #24\n",
    "        for j in i: #25\n",
    "            IG.append(j) #26\n",
    "        #27\n",
    "        Gate_Set_Index += 1 #28\n",
    "    #29\n",
    "    #ignoring 30\n",
    "    return result_array, {k: list(map(tuple, v)) for k, v in IL.items()}, cs_matrix(result_array,bell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e8ebc41-c1b7-4e51-ad8e-eefedf14e2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(3)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': X('qubit_count': 1), 'target': QubitSet([Qubit(4)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)], [Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(4)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)], [Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(4)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)], [Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(3), Qubit(4)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)], [Instruction('operator': H('qubit_count': 1), 'target': QubitSet([Qubit(3)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)]]\n",
      "{0: [(0, 3)], 1: [(0, 2)], 2: [(0, 2)], 3: [(0, 3)], 4: [(0, 4)]}\n",
      "[[2, 0, 0, 0, 1], [0, 2, 0, 0, 0], [0, 0, 2, 0, 0], [0, 0, 0, 2, 1], [1, 0, 0, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "Bernstein_Vazirani = Circuit().h(0).h(1).h(2).h(3).x(4).h(4).cnot(0,4).cnot(3,4).h(0).h(1).h(2).h(3)\n",
    "\n",
    "gate_states, IL, CS_matrix = algo_1(Bernstein_Vazirani)\n",
    "print(gate_states)\n",
    "\n",
    "print(IL)\n",
    "print(CS_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5279690f-44a4-4eb5-9fd5-c953310e8d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 4: 7, 3: 7}\n"
     ]
    }
   ],
   "source": [
    "print(greedyE_star(CS_matrix, [7, 2, 5, 8, 1, 0, 3, 4, 9, 6]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f9018fa-cf87-4ce5-9e2a-c696663a988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(Qubit(0), Qubit(4)): 1, (Qubit(3), Qubit(4)): 1}\n"
     ]
    }
   ],
   "source": [
    "def process_braket_circuit(circuit):\n",
    "    gate_set = defaultdict(int)\n",
    "    involvement_lists = defaultdict(list)\n",
    "    all_qubits = set()\n",
    "    for instruction in circuit.instructions:\n",
    "        if len(instruction.target) == 2:  # Check for 2-qubit gates\n",
    "            q1, q2 = instruction.target\n",
    "            gate_set[(q1, q2)] += 1\n",
    "            all_qubits.update([q1, q2])\n",
    "            for qubit in [q1, q2]:\n",
    "                if involvement_lists[qubit] and involvement_lists[qubit][-1][0] == len(involvement_lists[qubit]):\n",
    "                    involvement_lists[qubit][-1] = (len(involvement_lists[qubit]), involvement_lists[qubit][-1][1] + 1)\n",
    "                else:\n",
    "                    involvement_lists[qubit].append((len(involvement_lists[qubit]) + 1, 1))\n",
    "    num_qubits = max(all_qubits) + 1\n",
    "    coupling_strength_matrix = [[2 if i != j else 0 for j in range(num_qubits)] for i in range(num_qubits)]\n",
    "    return dict(gate_set), {k: list(map(tuple, v)) for k, v in involvement_lists.items()}, coupling_strength_matrix\n",
    "mod_gates, blank, not_used = process_braket_circuit(Bernstein_Vazirani)\n",
    "print(mod_gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff778d07-f246-4450-a77d-5fbbaee19838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_qubits(gate_set, involvement_lists, coupling_strength_matrix):\n",
    "    # Helper function to calculate the degree of a qubit\n",
    "    def calculate_degree(qubit, gate_set):\n",
    "        return sum([interactions for (q1, q2), interactions in gate_set.items() if qubit in [q1, q2]])\n",
    "    # Initialize mapped qubits dictionary and pending program qubits list\n",
    "    mapped_qubits = {}\n",
    "    pending_program_qubits = sorted(involvement_lists.keys(), key=lambda q: involvement_lists[q][0][0])\n",
    "    # Select a high-degree physical qubit for initial mapping\n",
    "    physical_qubits_degrees = [sum(row) for row in coupling_strength_matrix]\n",
    "    high_degree_physical_qubit = physical_qubits_degrees.index(max(physical_qubits_degrees))\n",
    "    # Map the first pending program qubit to the high-degree physical qubit\n",
    "    first_program_qubit = pending_program_qubits.pop(0)\n",
    "    mapped_qubits[first_program_qubit] = high_degree_physical_qubit\n",
    "    # Function to find the most suitable physical qubit for mapping\n",
    "    def find_suitable_physical_qubit(program_qubit):\n",
    "        best_physical_qubit = None\n",
    "        best_score = float('inf')\n",
    "        for pq, mapped_pq in mapped_qubits.items():\n",
    "            for neighbor_pq in range(len(coupling_strength_matrix[mapped_pq])):\n",
    "                if coupling_strength_matrix[mapped_pq][neighbor_pq] > 0 and neighbor_pq not in mapped_qubits.values():\n",
    "                    score = calculate_degree(program_qubit, gate_set) - coupling_strength_matrix[mapped_pq][neighbor_pq]\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_physical_qubit = neighbor_pq\n",
    "        return best_physical_qubit\n",
    "    # Map remaining program qubits to physical qubits\n",
    "    while pending_program_qubits:\n",
    "        program_qubit = pending_program_qubits.pop(0)\n",
    "        suitable_physical_qubit = find_suitable_physical_qubit(program_qubit)\n",
    "        if suitable_physical_qubit is not None:\n",
    "            mapped_qubits[program_qubit] = suitable_physical_qubit\n",
    "    return mapped_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0a2cf06-e6e6-4123-973c-5afcc2ac1720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4, 1: 0, 2: 3}\n"
     ]
    }
   ],
   "source": [
    "print(map_qubits(mod_gates, IL, CS_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a707e886-9402-44e4-afb3-70f77dd1fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernstein_vazirani():\n",
    "    circuit = Circuit().i(0).i(1).i(2).i(3).i(4).i(5).i(6).i(7).i(8).i(9).i(10).h(1).h(4).h(3).h(2).x(0).h(0).cnot(1,0).cnot(2,0).h(1).h(4).h(3).h(2)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e8f0b8c-25f2-4f18-9791-adc243307233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_circuit_simulation(circuit, noise_model):\n",
    "    device = LocalSimulator()\n",
    "    device = LocalSimulator(backend=\"braket_dm\")\n",
    "    circuit = noise_model.apply(circuit)\n",
    "    #print(c)\n",
    "    # run circuit (execute single TASK)\n",
    "    result = device.run(circuit, shots=1000).result()\n",
    "    # get measurement shots\n",
    "    counts = result.measurement_counts\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8527ee4-2e36-43e6-a880-ecec2a3cc6da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bv_circuit = bernstein_vazirani()\n",
    "bv_counts = run_circuit_simulation(bv_circuit, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ee7aea2-6e2f-4b6e-bb82-714213be439d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dictionary by values and extract the top 8 values\n",
    "highest_eight = sorted(bv_counts.values(), reverse=True)[:8]\n",
    "bv_fidelity = sum(highest_eight) / 1000\n",
    "bv_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfdeec2e-b975-4416-ad0e-c34caec00790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bernstein_vazirani():\n",
    "    circuit = Circuit().h(0).h(1).h(2).h(3).x(4).h(4).cnot(0,4).cnot(3,4).h(0).h(1).h(2).h(3)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f00d958f-3a73-42cf-bb9f-f8272f2554b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bv_circuit_bad = bernstein_vazirani()\n",
    "bv_counts_bad = run_circuit_simulation(bv_circuit, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a6ac658-c6ee-4915-b863-1f46ac49ea45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dictionary by values and extract the top 8 values\n",
    "highest_eight = sorted(bv_counts_bad.values(), reverse=True)[:8]\n",
    "bv_fidelity_bad = sum(highest_eight) / 1000\n",
    "bv_fidelity_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ffad9-2cbf-4078-926f-3a4c3018fd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
